{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client\n",
    "\n",
    "Demo of a client interacting with a remote agent that can use history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interact with this via API directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'output': 'The length of the word \"audioee\" is 7.'},\n",
       " 'callback_events': [],\n",
       " 'metadata': {'run_id': '468ae194-09e3-4318-b13f-724b283b8c4d'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "inputs = {\"input\": {\"input\": \"what is the length of the word audioee?\", \"chat_history\": []}}\n",
    "response = requests.post(\"http://localhost:8000/invoke\", json=inputs)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with this via the RemoteRunnable interface (to use in other chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_runnable = RemoteRunnable(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote runnable has the same interface as local runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  my name is eugene\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Nice to meet you, Eugene! How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  what's your name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I am an AI assistant and I don't have a personal name. You can simply call me \"Assistant\". How can I assist you further?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  what's was my name and what's its length?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Your name is Eugene and it has a length of 6 characters. Is there anything else you would like to know?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Bye bye human\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    human = input(\"Human (Q/q to quit): \")\n",
    "    if human in {\"q\", \"Q\"}:\n",
    "        print('AI: Bye bye human')\n",
    "        break\n",
    "    ai = await remote_runnable.ainvoke({\"input\": human, \"chat_history\": chat_history})\n",
    "    print(f\"AI: {ai['output']}\")\n",
    "    chat_history.extend([HumanMessage(content=human), AIMessage(content=ai['output'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream\n",
    "\n",
    "Please note that streaming alternates between actions and observations. It does not stream individual tokens!\n",
    "\n",
    "Please reference LangChain documentation to see how to stream individual tokens. \n",
    "\n",
    "At the time of writing 2024-01-18, the way to do this is using *astream_log*, and there's a proposed API using *astream_events* that will be merged soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "Hello! How can I assist you today?\n",
      "------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  my name is eugene\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "Nice to meet you, Eugene! How can I help you today?\n",
      "------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  what's the length of my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "Calling Tool ```word_length``` with input ```{'word': 'eugene'}```\n",
      "------\n",
      "Got result: ```6```\n",
      "------\n",
      "The length of your name, Eugene, is 6 characters.\n",
      "------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human (Q/q to quit):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Bye bye human\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    human = input(\"Human (Q/q to quit): \")\n",
    "    if human in {\"q\", \"Q\"}:\n",
    "        print('AI: Bye bye human')\n",
    "        break\n",
    "\n",
    "    ai = None\n",
    "    print(\"AI: \")\n",
    "    async for chunk in remote_runnable.astream({\"input\": human, \"chat_history\": chat_history}):\n",
    "        # Agent Action\n",
    "        if \"actions\" in chunk:\n",
    "            for action in chunk[\"actions\"]:\n",
    "                print(\n",
    "                    f\"Calling Tool ```{action['tool']}``` with input ```{action['tool_input']}```\"\n",
    "                )\n",
    "        # Observation\n",
    "        elif \"steps\" in chunk:\n",
    "            for step in chunk[\"steps\"]:\n",
    "                print(f\"Got result: ```{step['observation']}```\")\n",
    "        # Final result\n",
    "        elif \"output\" in chunk:\n",
    "            print(chunk['output'])\n",
    "            ai = AIMessage(content=chunk['output'])\n",
    "        else:\n",
    "            raise ValueError\n",
    "        print(\"------\")        \n",
    "    chat_history.extend([HumanMessage(content=human), ai])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
