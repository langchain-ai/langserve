{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client\n",
    "\n",
    "Demo of client interacting with the simple chain server, which deploys a chain that tells jokes about a particular topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interact with this via API directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': \"Why don't scientists trust atoms who play sports?\\n\\nBecause they make up everything!\",\n",
       " 'callback_events': []}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "inputs = {\"input\": {\"topic\": \"sports\"}}\n",
    "response = requests.post(\"http://localhost:8000/invoke\", json=inputs)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with this via the RemoteRunnable interface (to use in other chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_runnable = RemoteRunnable(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote runnable has the same interface as local runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = await remote_runnable.ainvoke({\"topic\": \"sports\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The client can also execute langchain code synchronously, and pass in configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "\n",
    "remote_runnable.batch([{\"topic\": \"sports\"}, {\"topic\": \"cars\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The server supports streaming (using HTTP server-side events), which can help interact with long responses in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async for chunk in remote_runnable.astream({\"topic\": \"bears, but a bit verbose\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurability\n",
    "\n",
    "The server chains have been exposed as configurable chains!\n",
    "\n",
    "```python \n",
    "\n",
    "model = ChatOpenAI(temperature=0.5).configurable_alternatives(\n",
    "    ConfigurableField(\n",
    "        id=\"llm\",\n",
    "        name=\"LLM\",\n",
    "        description=(\n",
    "            \"Decide whether to use a high or a low temperature parameter for the LLM.\"\n",
    "        ),\n",
    "    ),\n",
    "    high_temp=ChatOpenAI(temperature=0.9),\n",
    "    low_temp=ChatOpenAI(temperature=0.1),\n",
    "    default_key=\"medium_temp\",\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"tell me a joke about {topic}.\"\n",
    ").configurable_fields(  # Example of a configurable field\n",
    "    template=ConfigurableField(\n",
    "        id=\"prompt\",\n",
    "        name=\"Prompt\",\n",
    "        description=(\"The prompt to use. Must contain {topic}.\"),\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the configurability of the runnable in the API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await remote_runnable.ainvoke(\n",
    "    {\"topic\": \"sports\"},\n",
    "    config={\n",
    "        \"configurable\": {\"prompt\": \"how to say {topic} in french\", \"llm\": \"low_temp\"}\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
